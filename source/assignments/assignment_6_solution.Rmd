---
title: "Assignment 6"
author: "Nicole Cruz, Julia Haaf, Shravan Vasishth"
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(brms)
library(tidyverse)
library(ggplot2)
```

## Are subject relatives easier to process than object relatives (log-normal likelihood)? 

This is a classic question from the psycholinguistics literature: Are subject relatives easier to process than object relatives? The data come from Experiment 1 in a paper by Grodner and Gibson 2005.^[Grodner, D., & Gibson, E. (2005). Consequences of the serial nature of linguistic input for sentenial complexity. Cognitive Science, 29(2), 261-290.]

 *Scientific question*: Is there a subject relative advantage in reading?

Grodner and Gibson 2005 investigate an old claim in psycholinguistics that object relative clause (ORC) sentences are more difficult to process than \index{Subject relative clause} subject relative clause (SRC) sentences. One explanation for this predicted difference is that the distance between the relative clause verb (*sent* in the example below) and the head noun phrase of the relative clause (*reporter* in the example below) is longer in ORC vs. SRC. Examples are shown below. The relative clause is shown in square brackets.

 (1a) The *reporter* [who the photographer *sent* to the editor] was hoping for a good story. (ORC)

 (1b) The *reporter* [who *sent* the photographer to the editor] was hoping for a good story. (SRC)

 The underlying explanation has to do with memory processes: Shorter linguistic dependencies are easier to process due to either reduced interference or decay, or both. 

 In the Grodner and Gibson data, the dependent measure is reading time at the relative clause verb, (e.g., *sent*) of different sentences with either ORC or SRC. The dependent variable is in milliseconds and was measured in a self-paced reading task. Self-paced reading is a task where subjects read a sentence or a short text word-by-word or phrase-by-phrase, pressing a button to get each word or phrase displayed; the preceding word disappears every time the button is pressed.

 For this experiment, we are expecting longer reading times at the relative clause verbs of ORC sentences in comparison to the relative clause verb of SRC sentences.

```{r open_grodneretal, message = FALSE}
load("data/df_gg05_rc.rda")
head(df_gg05_rc)
```

You should use a sum coding for the predictors. Here, object relative clauses (`"objgaps"`) are coded $+1/2$, subject relative clauses $-1/2$.

```{r}
df_gg05_rc <- df_gg05_rc %>%
  mutate(c_cond = if_else(condition == "objgap", 1/2, -1/2))
```

You should be able to now fit a "maximal" model (correlated varying intercept and slopes for subjects and for items) assuming a log-normal likelihood.

(a) Specify the statistical model and define priors for all parameters in the model. *Hint:* To assess reasonable ranges of values for the mean and sigma parameter of a lognormal distribution, you might want to simulate lognormal data for different values using `rlnorm()`
(b) Examine the effect of relative clause attachment site (the predictor `c_cond`) on reading times `RT` ($\beta_1$).
(c) Estimate the median difference between relative clause attachment sites in milliseconds, and report the mean and 95% CI.
(d) Inspect individual differences in the subject relative advantage effect. Are there participants with effects in opposite directions?
(e) Do a sensitivity analysis. What is the estimate of the effect ($\beta_1$) under different priors? What is the difference in milliseconds between conditions under different priors?

### Solution

### (a)

We are going to fit the data with the following log-normal likelihood:

 \begin{equation}
  Y_{ijk} \sim \mbox{LogNormal}(\beta_1 + \delta_{i,0} + \omega_{k,0} + X_{j} \cdot  (\beta + \delta_{i,1}+ \omega_{k,1}), \sigma)
  \end{equation}

We should pay attention to use a not too tight prior for $\beta_1$:


* Priors:
 \begin{equation}
 \begin{aligned}
   \beta_0 & \sim \mbox{Normal}(5.5, 0.8) \\
   \beta_1  & \sim \mbox{Normal}(0, 0.1) \\
    \sigma  &\sim \mbox{Normal}_+(0, 1)
 \end{aligned}
 \end{equation}

Here, we will need priors for the group-level parameters. Given that we assume a correlation between by-subject intercept and slope, and by-item intercept and slope, our model has the following structure which requires us to assign priors to $\Sigma_\delta$ and $\Sigma_\omega$

 \begin{equation}
 \begin{aligned}
    {\begin{pmatrix}
    \delta_{i,0} \\
    \delta_{i,1}
    \end{pmatrix}}
   &\sim {\mathcal {N}}
    \left(
   {\begin{pmatrix}
    0\\
    0
   \end{pmatrix}}
 ,\boldsymbol{\Sigma_\delta} \right) \\
     {\begin{pmatrix}
    \omega_{k,0} \\
    \omega_{k,1}
    \end{pmatrix}}
   &\sim {\mathcal {N}}
    \left(
   {\begin{pmatrix}
    0\\
    0
   \end{pmatrix}}
 ,\boldsymbol{\Sigma_\omega} \right)
 \end{aligned}
 \end{equation}

\begin{equation}
\begin{aligned}
 \boldsymbol{\Sigma_\delta} & =
{\begin{pmatrix}
\sigma_{\delta_0}^2 & \rho_\delta \sigma_{\delta_0} \sigma_{\delta_1} \\
\rho_\delta \sigma_{\delta_0} \sigma_{\delta_1} & \sigma_{\delta_1}^2
\end{pmatrix}}\\
 \boldsymbol{\Sigma_\omega} & =
{\begin{pmatrix}
\sigma_{\omega_0}^2 & \rho_\omega \sigma_{\omega_0} \sigma_{\omega_1} \\
\rho_\omega \sigma_{\omega_0} \sigma_{\omega_1} & \sigma_{\omega_1}^2
\end{pmatrix}}
 \end{aligned}
\end{equation}

In practice this means that we need priors for the by-subject and by-item variances and correlations:
\begin{equation}
\begin{aligned}
\sigma_{\delta_0} &\sim Normal_+(0,1)\\
\sigma_{\delta_1} &\sim Normal_+(0,1)\\
\rho_\delta &\sim LKJcorr(2) \\
\sigma_{\omega_0} &\sim Normal_+(0,1)\\
\sigma_{\omega_1} &\sim Normal_+(0,1)\\
\rho_\omega &\sim LKJcorr(2) \\
\end{aligned}
\end{equation}

Read the data:

We're ready to fit a model now:

```{r, message = FALSE, results = "hide", cache=TRUE}
fit_df_gg05_rc <- brm(RT ~ c_cond + (c_cond | subj) + (c_cond | item),
  family = lognormal(),
  iter = 10000,
  prior =
    c(
      prior(normal(5.5, 0.7), class = Intercept),
      prior(normal(0, .1), class = b),
      prior(normal(0, 1), class = sigma),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_gg05_rc,
  control=list(adapt_delta=0.99, max_treedepth=15)
)
```

### (b) Examine the effect of relative clause attachment site (the predictor `c_cond`) on reading times `RT` in log-scale.

We'll focus on $\beta$:

```{r}
posterior_summary(fit_df_gg05_rc, variable = "b_c_cond")
```

### (b) Estimate the median difference between relative clause attachment sites in milliseconds, and report the mean and 95% CI.

```{r}
beta0 <- as_draws_df(fit_df_gg05_rc)$b_Intercept
beta1 <- as_draws_df(fit_df_gg05_rc)$b_c_cond
# Difference between object RC coded as .5 and subject RC coded as .5
effect <- exp(beta0 + beta1 * .5) - exp(beta0 + beta1 * -.5)
c(mean = mean(effect), quantile(effect, c(.025,.975)))
```

## (c)


```{r, fig.asp = 1.4, fig.width=5}
# We get the by subject effects in a data frame where each adjustment
# is in each column.
by_subj_effect <- data.frame(coef(fit_df_gg05_rc)$subj[,, "c_cond"]) %>%
  bind_rows() %>%
  # We add a column to identify that the model,
  # and one with the subject labels:
  mutate(
    subj = unique(df_gg05_rc$subj))%>%
  arrange(Estimate) %>%
  mutate(subj = factor(subj, levels = subj))


ggplot(
  by_subj_effect,
  aes(
    ymin = Q2.5, ymax = Q97.5, x = subj, y = Estimate
  )
) +
  geom_errorbar() +
  geom_point() +
  # We'll also add the mean and 95% CrI of the overall difference
  # to the plot:
  geom_hline(
    yintercept =
      posterior_summary(fit_df_gg05_rc)["b_c_cond", "Estimate"]
  ) +
  geom_hline(
    yintercept =
      posterior_summary(fit_df_gg05_rc)["b_c_cond", "Q2.5"],
    linetype = "dotted", linewidth = 0.5
  ) +
  geom_hline(
    yintercept =
      posterior_summary(fit_df_gg05_rc)["b_c_cond", "Q97.5"],
    linetype = "dotted", linewidth = 0.5
  ) +
  xlab("Change in reading times") +
  coord_flip() +
  theme_light(base_size = 16)
```

### (d) Do a sensitivity analysis. What is the estimate of the effect ($\beta$) under different priors? What is the difference in milliseconds between conditions under different priors?

Next, we do a sensitivity analysis using a tighter prior for $\beta$, $\beta_1 \sim Normal(0, 0.01)$:

```{r, message = FALSE, results = "hide", cache=TRUE}
fit_df_gg05_rc2 <- brm(RT ~ c_cond + (c_cond | subj) + (c_cond | item),
  family = lognormal(),
  prior =
    c(
      prior(normal(5.5, 0.7), class = Intercept),
      prior(normal(0, 0.01), class = b),
      prior(normal(0, 1), class = sigma),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_gg05_rc,
  control=list(adapt_delta=0.99, max_treedepth=15)
)
```

```{r, fig.height = 11}
posterior_summary(fit_df_gg05_rc2, variable = "b_c_cond")
```

And here we use the prior, $\beta_1 \sim Normal(0, 1)$:

```{r, message = FALSE, results = "hide", cache=TRUE}
fit_df_gg05_rc3 <- brm(RT ~ c_cond + (c_cond | subj) + (c_cond | item),
  family = lognormal(),
  prior =
    c(
      prior(normal(5.5, 0.7), class = Intercept),
      prior(normal(0, 1), class = b),
      prior(normal(0, 1), class = sigma),
      prior(normal(0, 1), class = sd),
      prior(lkj(2), class = cor)
    ),
  data = df_gg05_rc,
  control=list(adapt_delta=0.99, max_treedepth=15)
)
```

```{r, fig.height = 11}
posterior_summary(fit_df_gg05_rc3, variable = "b_c_cond")
```
We can summarize the estimates of $\beta$ given different priors in the following way:

```{r, echo = FALSE, results = "asis"}
select <- dplyr::select

list(fit_df_gg05_rc, fit_df_gg05_rc2, fit_df_gg05_rc3) %>%
  map_dfr(~
  posterior_summary(.x, variable = "b_c_cond") %>%
    as_tibble() %>%
    select(-Est.Error)) %>%
  mutate("Prior for $\\beta$" = c("Normal(0,.01)", "Normal(0,.1)", "Normal(0,1)")) %>%
  knitr::kable(escape = FALSE)
```

We can take a look at the estimate for the difference between conditions in milliseconds:

```{r}
beta0 <- as_draws_df(fit_df_gg05_rc)$b_Intercept
beta1 <- as_draws_df(fit_df_gg05_rc)$b_c_cond
diff1 <- exp(beta0 + beta1/2) - exp(beta0 - beta1/2)
c(mean = mean(diff1), quantile(diff1, c(.025, .975)))
```

If we repeat this with each model, we can take a look at the effect of the prior on the difference between conditions:

```{r, echo = FALSE, results ="asis"}
list(fit_df_gg05_rc, fit_df_gg05_rc2, fit_df_gg05_rc3) %>%
  map_dfr(~ {
    beta0 <- as_draws_df(.x)$b_Intercept
    beta1 <- as_draws_df(.x)$b_c_cond
    diff <- exp(beta0 + beta1/2) - exp(beta0 - beta1/2)
    c(mean = mean(diff), quantile(diff, c(.025, .975))) %>%
      bind_rows() %>%
      setNames(c("Estimate (ms)", "Q2.5", "Q97.5"))
  }) %>%
  mutate("Prior for $\\beta_1$" = c("Normal(0,.01)", "Normal(0,.1)", "Normal(0,1)")) %>%
  knitr::kable(escape = FALSE)
```

This sensitivity shows us that the posterior changes quite a lot under different priors; depending on what we consider to be a reasonable prior (i.e., depending on our prior beliefs), the inference that we derive from the model and data can vary quite a bit when the data are relatively sparse, as in this case.
